{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354a5db3-57b1-4d07-93f8-87d565eab9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.sparse import hstack\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bfbebe-716e-41a8-8aae-185250bd7d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_path = 'sepsis_diab_pt_all_new1.xlsx'  # Update if needed\n",
    "# Load all sheets\n",
    "sheets = pd.ExcelFile(file_path)\n",
    "sheet_names = sheets.sheet_names\n",
    "print(\"Available Sheets:\", sheet_names)\n",
    "\n",
    "# Load individual sheets\n",
    "admission_data = sheets.parse('sepsis_pt_all_admission details')\n",
    "lab_events = sheets.parse('sepsis_lab_events')\n",
    "microbiology_events = sheets.parse('microbiology events')\n",
    "prescription_data = sheets.parse('prescriptoin')\n",
    "poe_data = sheets.parse('poe')\n",
    "\n",
    "print(\"admission_data shape\", admission_data.shape)\n",
    "print(\"lab_events shape\", lab_events.shape)\n",
    "print(\"microbiology_events\", microbiology_events.shape)\n",
    "print(\"prescription_data\", prescription_data.shape)\n",
    "print(\"poe_data\",poe_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ff3b0d-a8b8-49ff-be2a-843123b0b203",
   "metadata": {},
   "outputs": [],
   "source": [
    "#admission_data\n",
    "print(\"admission_data info\",admission_data[['subject_id','hadm_id','admission_type','edhours','hospital_expire_flag','dx_1_code','sepsis_flag','drg_code','diabetic_flag','gender','anchor_age']].info())\n",
    "print(\"head of admission data\", admission_data[['subject_id','hadm_id','admission_type','edhours','hospital_expire_flag','dx_1_code','sepsis_flag','drg_code','diabetic_flag','gender','anchor_age']].head())\n",
    "\n",
    "admission_data['edhours']=admission_data['edhours'].fillna(0)\n",
    "admission_data['anchor_age']=admission_data['anchor_age'].fillna(admission_data['anchor_age'].mean())\n",
    "admission_data['age_group'] = pd.cut(admission_data['anchor_age'], bins=[0, 18, 40, 65, 120],labels=['Child', 'Young Adult', 'Adult', 'Senior'])\n",
    "\n",
    "#admission data cleaning\n",
    "admission_data = admission_data.drop_duplicates(subset='hadm_id')\n",
    "\n",
    "admission_data[['subject_id','hadm_id','admission_type','edhours','hospital_expire_flag','dx_1_code','sepsis_flag','drg_code','diabetic_flag','gender','anchor_age','age_group',\"LOS\"]].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a830823-2078-433d-bf86-cc54019759d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "admission_data['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb891000-650f-4f91-927f-f1b01540ff72",
   "metadata": {},
   "outputs": [],
   "source": [
    "admission_data['gender']=admission_data['gender'].apply(lambda x:1 if x==\"M\" else 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb93c40-e7f6-4567-aeaa-abd77fee2e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "admission_data['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c8fe73-f984-4f26-99e0-73d3d733ec1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#analysing prescription data\n",
    "print(\"prescription_data info\", prescription_data.info())\n",
    "print(\"prescription_data head\", prescription_data.head(5))\n",
    "prescription_data = prescription_data.drop_duplicates(subset=['hadm_id', 'drug'])\n",
    "prescription_summary = prescription_data.groupby('hadm_id')['drug'].apply(lambda x: '|'.join(x.unique()))\n",
    "print(\"prescription_data summary df\", prescription_summary.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a304f8-67e2-4f8c-82c1-4958b9f3dc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Microbiology events\n",
    "print(\"microbiology_events info\", microbiology_events.info())\n",
    "print(\"microbiology_events head\", microbiology_events.head(3))      \n",
    "microbiology_events['hadm_id']=microbiology_events['hadm_id'].fillna(microbiology_events['hadm_id.1'])\n",
    "microbiology_events['hadm_id']=microbiology_events['hadm_id'].astype('int')\n",
    "microbiology_events = microbiology_events.dropna(subset=['hadm_id', 'spec_type_desc'])\n",
    "microbiology_summary = microbiology_events.groupby('hadm_id')['spec_type_desc'].apply(lambda x: '|'.join(x.unique()))\n",
    "microbiology_flags = microbiology_events['spec_type_desc'].str.get_dummies(sep=',').groupby(microbiology_events['hadm_id']).max()\n",
    "print(\"microbiology_summary\",microbiology_summary.head(2))\n",
    "print(\"microbiology_summary\",microbiology_summary.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88e0921-dc2c-40ef-8b0d-a6e3135a50eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## POE data\n",
    "print(\"poe_data info\",poe_data.info())\n",
    "print(\"poe_data head\",poe_data.head())\n",
    "\n",
    "poe_data['order_type'] = poe_data['order_type'].str.strip()\n",
    "poe_summary = poe_data.groupby('hadm_id')['order_type'].apply(lambda x: '|'.join(x.unique()))\n",
    "poe_counts = poe_data.groupby(['hadm_id', 'order_type']).size().unstack(fill_value=0)\n",
    "print(\"poe_summary info\",poe_summary.info())\n",
    "print(\"poe_summary head\",poe_summary.head())\n",
    "print(\"poe_counts info\",poe_counts.info())\n",
    "print(\"poe_counts head\",poe_counts.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8863ce3-58f1-4edd-8260-92aed15874a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "admission_data['drg_code']=admission_data['drg_code'].astype(str)\n",
    "admission_data['dx_1_code']=admission_data['dx_1_code'].astype(str)\n",
    "\n",
    "# --- Step 2: Encode Features ---\n",
    "## Categorical encoding\n",
    "ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "admission_encoded = pd.DataFrame(\n",
    "    ohe.fit_transform(admission_data[['admission_type', 'drg_code', 'dx_1_code','gender','age_group']]),\n",
    "    columns=ohe.get_feature_names_out())\n",
    "## Numerical scaling\n",
    "scaler = StandardScaler()\n",
    "admission_data['scaled_edhours'] = scaler.fit_transform(admission_data[['edhours']])\n",
    "admission_data['scaled_los'] = scaler.fit_transform(admission_data[['LOS']])\n",
    "\n",
    "admission_data_ohc = pd.concat(\n",
    "    [\n",
    "        admission_data[['hadm_id', 'gender', 'age_group', 'scaled_edhours', 'scaled_los','LOS']].reset_index(drop=True),\n",
    "        admission_encoded.reset_index(drop=True)\n",
    "    ],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# --- Step 3: Merge Data ---\n",
    "\n",
    "merged_data = admission_data_ohc.merge(\n",
    "    prescription_summary, on='hadm_id', how='left'\n",
    ").merge(\n",
    "    microbiology_summary, on='hadm_id', how='left'\n",
    ").merge(\n",
    "    microbiology_flags, on='hadm_id', how='left'\n",
    ").merge(\n",
    "    poe_counts, on='hadm_id', how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd9fa62-8910-4ab3-9434-cd4262e652a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c48410-a9ed-4714-aa54-61c54a5583e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4e9043-5410-4e9c-99d5-2cec7795247c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264de940-dca5-4954-af7a-24570d5ecbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(merged_data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2499632-ee5f-4caa-9546-739aef5c028c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7a30cd-5070-4fa4-a9eb-702e42d24af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data[['ABSCESS', 'ASPIRATE', 'BILE', 'BIOPSY', 'BLOOD CULTURE', 'BLOOD CULTURE ( MYCO/F LYTIC BOTTLE)', 'BONE MARROW', 'BONE MARROW - CYTOGENETICS', 'BRONCHIAL WASHINGS', 'BRONCHOALVEOLAR LAVAGE', 'Blood (CMV AB)', 'Blood (EBV)', 'Blood (LYME)', 'Blood (Malaria)', 'Blood (Toxo)', 'CATHETER TIP-IV', 'CSF;SPINAL FLUID', 'DIALYSIS FLUID', 'DIRECT ANTIGEN TEST FOR VARICELLA-ZOSTER VIRUS', 'Direct Antigen Test for Herpes Simplex Virus Types 1 & 2', 'FECAL SWAB', 'FLUID', 'FLUID RECEIVED IN BLOOD CULTURE BOTTLES', 'FOOT CULTURE', 'FOREIGN BODY', 'IMMUNOLOGY', 'Immunology (CMV)', 'Influenza A/B by DFA', 'Isolate', 'JOINT FLUID', 'MRSA SCREEN', 'Mini-BAL', 'OTHER', 'PERITONEAL FLUID', 'PLEURAL FLUID', 'POSTMORTEM CULTURE', 'Rapid Respiratory Viral Screen & Culture', 'SEROLOGY/BLOOD', 'SKIN SCRAPINGS', 'SPUTUM', 'STOOL', 'STOOL (RECEIVED IN TRANSPORT SYSTEM)', 'SWAB', 'Staph aureus swab', 'THROAT CULTURE', 'THROAT FOR STREP', 'TISSUE', 'URINE', 'VIRAL CULTURE: R/O CYTOMEGALOVIRUS', 'XXX', 'ADT orders', 'Blood Bank', 'Cardiology', 'Consults', 'Critical Care', 'General Care', 'Hemodialysis', 'IV therapy', 'Lab', 'Medications', 'Neurology', 'Nutrition', 'Radiology', 'Respiratory', 'TPN']]=merged_data[['ABSCESS', 'ASPIRATE', 'BILE', 'BIOPSY', 'BLOOD CULTURE', 'BLOOD CULTURE ( MYCO/F LYTIC BOTTLE)', 'BONE MARROW', 'BONE MARROW - CYTOGENETICS', 'BRONCHIAL WASHINGS', 'BRONCHOALVEOLAR LAVAGE', 'Blood (CMV AB)', 'Blood (EBV)', 'Blood (LYME)', 'Blood (Malaria)', 'Blood (Toxo)', 'CATHETER TIP-IV', 'CSF;SPINAL FLUID', 'DIALYSIS FLUID', 'DIRECT ANTIGEN TEST FOR VARICELLA-ZOSTER VIRUS', 'Direct Antigen Test for Herpes Simplex Virus Types 1 & 2', 'FECAL SWAB', 'FLUID', 'FLUID RECEIVED IN BLOOD CULTURE BOTTLES', 'FOOT CULTURE', 'FOREIGN BODY', 'IMMUNOLOGY', 'Immunology (CMV)', 'Influenza A/B by DFA', 'Isolate', 'JOINT FLUID', 'MRSA SCREEN', 'Mini-BAL', 'OTHER', 'PERITONEAL FLUID', 'PLEURAL FLUID', 'POSTMORTEM CULTURE', 'Rapid Respiratory Viral Screen & Culture', 'SEROLOGY/BLOOD', 'SKIN SCRAPINGS', 'SPUTUM', 'STOOL', 'STOOL (RECEIVED IN TRANSPORT SYSTEM)', 'SWAB', 'Staph aureus swab', 'THROAT CULTURE', 'THROAT FOR STREP', 'TISSUE', 'URINE', 'VIRAL CULTURE: R/O CYTOMEGALOVIRUS', 'XXX', 'ADT orders', 'Blood Bank', 'Cardiology', 'Consults', 'Critical Care', 'General Care', 'Hemodialysis', 'IV therapy', 'Lab', 'Medications', 'Neurology', 'Nutrition', 'Radiology', 'Respiratory', 'TPN']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14a42a2-95f5-47ae-ab6b-0130a7e6f816",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c16ac27-3b08-47f7-861d-117fe80dc7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9532a5-63af-4922-90f0-7c10350b05b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Final Feature Matrix (Exclude 'hadm_id' for modeling)\n",
    "#feature_matrix = merged_data.drop(columns=['hadm_id'], errors='ignore')\n",
    "\n",
    "# Export prepared data\n",
    "merged_data.to_csv('RL_clinicalpathwayprepared_data_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9fbffe-6610-42b3-945e-57b8a901027f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Action mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a41ea1-584c-4d57-aa16-47a0dbcc7fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_drugs=prescription_data['drug'].unique().tolist()\n",
    "unique_microbiology_events=microbiology_events['spec_type_desc'].unique().tolist()\n",
    "unique_poe_list=poe_data['order_type'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bea5c83-02b7-4bc9-8729-f7c89560214b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty action_metadata dictionary\n",
    "action_metadata = {}\n",
    "\n",
    "# Assign categories to each action\n",
    "for drug in unique_drugs:\n",
    "    action_metadata[drug] = \"drug\"\n",
    "\n",
    "for event in unique_microbiology_events:\n",
    "    action_metadata[event] = \"test\"\n",
    "\n",
    "for poe in unique_poe_list:\n",
    "    action_metadata[poe] = \"poe\"\n",
    "\n",
    "# Print the resulting action_metadata for verification\n",
    "print(action_metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374eb467-e1b0-48fa-8ab0-159c964ded1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_actions = unique_drugs + unique_microbiology_events + unique_poe_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72356abc-3b12-4f21-a273-0c2c81153fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9b7ab4-6a64-4138-802f-92818688173b",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_map = {index: action for index, action in enumerate(all_actions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487982a1-268e-47a7-a030-e0d29b1566ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Action Map:\")\n",
    "print(action_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daa01ef-9042-4b54-ad40-28555d2b6543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9465d160-19c9-446a-8530-d26afa284e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged_data.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ca3e54-4b1c-4451-a12c-6f5434689dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "los_max = merged_data[\"LOS\"].max() \n",
    "data=merged_data.drop(columns=['hadm_id','age_group','drug','spec_type_desc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fafca7-b0e8-4f6b-b51f-2e15c7b76361",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ClinicalEnvironment(data, action_map, los_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4264f4-7e0a-4696-95bd-e0bc45dd0eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6734b10d-4759-463e-8840-6d87cc7aa6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc7351c-76c9-4eda-9b92-6d1fbdb52aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class ClinicalEnvironment:\n",
    "    def __init__(self, data, action_map, los_max, action_metadata):\n",
    "        \"\"\"\n",
    "        Initialize the clinical environment.\n",
    "\n",
    "        Parameters:\n",
    "        - data: Prepared dataset with one-hot encoded features for drugs, lab tests, and POEs.\n",
    "        - action_map: A mapping of action indices to clinical actions (drugs, lab tests, orders).\n",
    "        - los_max: Maximum LOS in the dataset (used for normalization).\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.action_map = action_map\n",
    "        self.los_max = los_max\n",
    "        self.current_index = 0\n",
    "        self.done = False \n",
    "        self.action_metadata = action_metadata\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Reset the environment by selecting a random admission.\n",
    "\n",
    "        Returns:\n",
    "        - Initial state as a NumPy array.\n",
    "        \"\"\"\n",
    "        self.current_index = np.random.randint(0, len(self.data))\n",
    "        self.done = False\n",
    "        return self.data.iloc[self.current_index].drop([\"LOS\"]).values\n",
    "\n",
    "    def step(self, action_index):\n",
    "        \"\"\"\n",
    "        Take an action and transition to the next state.\n",
    "\n",
    "        Parameters:\n",
    "        - action_index: Index of the selected action.\n",
    "\n",
    "        Returns:\n",
    "        - next_state: Next state as a NumPy array.\n",
    "        - reward: Reward for the taken action.\n",
    "        - done: Whether the episode has ended.\n",
    "        \"\"\"\n",
    "        row = self.data.iloc[self.current_index]\n",
    "        action = self.action_map[action_index]\n",
    "        \n",
    "        reward = self._calculate_reward(row[\"LOS\"], action)\n",
    "        \n",
    "        # Simulate a simple transition: State remains static.\n",
    "        next_state = row.drop([\"LOS\"]).values + self._action_effect(action)\n",
    "        \n",
    "        # End the episode after one step (simplified setup).\n",
    "        self.done = self.current_index >= len(self.data) - 1  # Replace with better condition\n",
    "        return next_state, reward, self.done\n",
    "\n",
    "    def _action_effect(self, action):\n",
    "        \"\"\"\n",
    "        Simulate the effect of an action on the current state.\n",
    "        \"\"\"\n",
    "        # Example: Return an array of zeros (no state change) or customize as needed.\n",
    "        return np.zeros(len(self.data.columns) - 1)  # Adjust for actual features\n",
    "\n",
    "\n",
    "    def _calculate_reward(self, los, action):\n",
    "        category = self.action_metadata.get(action, \"unknown\")\n",
    "        normalized_reward = (self.los_max - los) / self.los_max\n",
    "\n",
    "        if category == \"drug\":\n",
    "            normalized_reward += 0.1  # Example logic for drugs\n",
    "        elif category == \"test\":\n",
    "            normalized_reward += 0.05  # Example logic for tests\n",
    "        elif category == \"poe\":\n",
    "            normalized_reward -= 0.05  # Example logic for POEs\n",
    "\n",
    "        return normalized_reward\n",
    "\n",
    "        \n",
    "    def get_initial_state_old(self, query_dict):\n",
    "        \"\"\"\n",
    "        Convert a patient query dictionary into the initial state format\n",
    "        based on the data columns of the environment.\n",
    "        \"\"\"\n",
    "        # Ensure query_dict has the same keys as data columns minus \"los\"\n",
    "        state = []\n",
    "        print(\"len of columns inside initial state\", len(self.data.columns))\n",
    "        #for col in self.data.columns:\n",
    "        #    if col == \"los\":\n",
    "        #        continue  # Skip the target column\n",
    "        #    state.append(query_dict.get(col, 0))  # Default to 0 if key is missing\n",
    "        feature_columns = [col for col in self.data.columns if col != \"LOS\"]\n",
    "        state = [query_dict.get(col, 0) for col in feature_columns]\n",
    "\n",
    "        return np.array(state, dtype=np.float32)\n",
    "\n",
    "    def get_initial_state(self, query_dict):\n",
    "        \"\"\"\n",
    "        Convert a patient query dictionary into the initial state format\n",
    "        based on the data columns of the environment.\n",
    "        \"\"\"\n",
    "        # Ensure query_dict has the same keys as data columns minus \"los\"\n",
    "        # Collect column names excluding \"los\"\n",
    "        feature_columns = [col for col in self.data.columns if col != \"LOS\"]\n",
    "        state = []\n",
    "    \n",
    "        print(\"len of columns inside initial state\", len(feature_columns))\n",
    "        for col in feature_columns:\n",
    "            state.append(query_dict.get(col, 0))  # Default to 0 if key is missing\n",
    "        return np.array(state, dtype=np.float32)\n",
    "\n",
    "\n",
    "##DQN Model\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import deque\n",
    "import random\n",
    "\n",
    "# Define the DQN model\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, state_size, action_size):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, action_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835891ab-679e-43c3-8ec6-469aae8f5618",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(list(merged_data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93865b3a-8136-4798-bd20-0d3221d2903b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "state_size = len(data.columns) - 1  # Number of features\n",
    "action_size = len(action_map)       # Number of possible actions\n",
    "batch_size = 64\n",
    "gamma = 0.99                        # Discount factor\n",
    "epsilon = 1.0                       # Initial exploration rate\n",
    "epsilon_min = 0.01\n",
    "epsilon_decay = 0.995\n",
    "learning_rate = 0.001\n",
    "target_update = 10                  # Frequency of target network update\n",
    "episodes = 1000\n",
    "\n",
    "# Initialize environment and networks\n",
    "env = ClinicalEnvironment(data, action_map, los_max,action_metadata)\n",
    "q_network = DQN(state_size, action_size)\n",
    "target_network = DQN(state_size, action_size)\n",
    "target_network.load_state_dict(q_network.state_dict())\n",
    "optimizer = optim.Adam(q_network.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "max_grad_norm = 1.0\n",
    "\n",
    "def compute_target(q_values, target_q_values, actions, rewards, dones):\n",
    "    \"\"\"\n",
    "    Compute the target Q-value using Double DQN logic.\n",
    "    \"\"\"\n",
    "    best_actions = torch.argmax(q_values, dim=1)  # Actions selected by Q-network\n",
    "    max_target_q = target_q_values.gather(1, best_actions.unsqueeze(1)).squeeze(1)\n",
    "    return rewards + (1 - dones) * gamma * max_target_q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d937e36-4fe9-4691-880e-4d00cc178785",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d74f93-a3ba-4ccd-a04b-cbecae7c7a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_steps = 100  # Maximum steps per episode\n",
    "memory = deque(maxlen=2000)\n",
    "best_reward = float('-inf')\n",
    "\n",
    "for episode in range(episodes):\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    steps = 0\n",
    "\n",
    "    while not done and steps < max_steps:\n",
    "        steps += 1\n",
    "        action = select_action(state, epsilon)\n",
    "        next_state, reward, done = env.step(action)\n",
    "        total_reward += reward\n",
    "\n",
    "        memory.append((state, action, reward, next_state, done))\n",
    "        state = next_state\n",
    "\n",
    "        # Skip training if memory is insufficient\n",
    "        if len(memory) < batch_size:\n",
    "            continue\n",
    "\n",
    "        # Sample and train\n",
    "        batch = random.sample(memory, batch_size)\n",
    "        states, actions, rewards, next_states, dones = zip(*batch)\n",
    "\n",
    "        states = torch.tensor(states, dtype=torch.float32)\n",
    "        actions = torch.tensor(actions, dtype=torch.long)\n",
    "        rewards = torch.tensor(rewards, dtype=torch.float32)\n",
    "        next_states = torch.tensor(next_states, dtype=torch.float32)\n",
    "        dones = torch.tensor(dones, dtype=torch.float32)\n",
    "\n",
    "        q_values = q_network(states).gather(1, actions.unsqueeze(1)).squeeze()\n",
    "        with torch.no_grad():\n",
    "            target_q_values = rewards + gamma * (1 - dones) * target_network(next_states).max(1)[0]\n",
    "\n",
    "        loss = loss_fn(q_values, target_q_values)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(q_network.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "    epsilon = max(epsilon_min, epsilon * epsilon_decay)\n",
    "\n",
    "    if episode % target_update == 0:\n",
    "        target_network.load_state_dict(q_network.state_dict())\n",
    "\n",
    "    if total_reward > best_reward:\n",
    "        best_reward = total_reward\n",
    "        torch.save(q_network.state_dict(), \"best_q_network.pth\")\n",
    "\n",
    "    print(f\"Episode {episode + 1}/{episodes}, Total Reward: {total_reward:.2f}, Epsilon: {epsilon:.2f}\")\n",
    "\n",
    "print(\"Training Complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0e11fd-49bd-4ce8-9ad0-fd2f6af592c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(q_network.state_dict(), \"dqn_clinical_pathway1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af2e106-d6b3-4e33-92cc-edb4ae997818",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_network.load_state_dict(torch.load(\"dqn_clinical_pathway1.pth\"))\n",
    "q_network.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44871cf-0df8-47c6-9dcd-64f627a5426b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_pathway(env, model, query_dict):\n",
    "    # Convert query_dict to the initial state format\n",
    "    state = env.get_initial_state(query_dict)\n",
    "    #print(\"State vector shape:\", len(state))  # Length of the state vector\n",
    "    #print(\"Number of columns in input data:\", len(state.columns) - 1)  # Exclude 'los'\n",
    "    #print(\"Number of columns in data:\", len(env.data.columns) - 1)  # Exclude 'los'\n",
    "    #print(\"Columns in data:\", list(env.data.columns))\n",
    "    #print(\"QNetwork input_dim:\", model.fc1.in_features)  # Should match len(state)\n",
    "    #print(\"QNetwork output_dim:\", model.fc3.out_features)  # Should match len(env.action_map)\n",
    "    \n",
    "    recommendations = []\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0)\n",
    "        print(\"State tensor shape:\", state_tensor.shape)\n",
    "        with torch.no_grad():\n",
    "            action = torch.argmax(model(state_tensor)).item()\n",
    "        next_state, reward, done = env.step(action)\n",
    "        recommendations.append({\n",
    "            \"action\": env.action_map[action],\n",
    "            \"reward\": reward\n",
    "        })\n",
    "        state = next_state\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "def recommend_pathway_other(env, model, query_dict, max_steps=100):\n",
    "    state = torch.FloatTensor(env.get_initial_state(query_dict)).unsqueeze(0)\n",
    "    pathway = []\n",
    "    \n",
    "    for step in range(max_steps):\n",
    "        q_values = model(state)\n",
    "        print(f\"Q-values: {q_values}\")\n",
    "        action_index = torch.argmax(q_values).item()\n",
    "        action_name = env.action_map[action_index]\n",
    "        next_state, reward, done = env.step(action_index)\n",
    "        pathway.append({\"action\": action_name, \"reward\": reward})\n",
    "        \n",
    "        #if done:\n",
    "        #    break\n",
    "        state = torch.FloatTensor(next_state).unsqueeze(0)\n",
    "    \n",
    "    return pathway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510b2fed-21d7-4576-b644-f5edc33d21b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c21cece-b5bf-43ca-a797-923b8eb6854b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_dict = {\n",
    "    #\"gender\": 1,  # Encoded\n",
    "    #\"age\": 56,\n",
    "    \"drg_code_871\": 1,\n",
    "    #\"age_group_Senior\": 1,  # Encoded\n",
    "    #\"ed_hours\": 3.5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565b8701-56ac-41bf-a464-e6241654e2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = recommend_pathway(env, q_network, query_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d51099b-d314-47e2-be76-5d562072c473",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63abbdb-575b-41cd-afa7-cf60a83af25c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
