{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357a6d35-10b5-43e5-a0b3-111585d2fb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd75e7e3-d583-43c8-8754-115e20fe69d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_path = 'sepsis_diab_pt_all_v2.xlsx'  # Update if needed\n",
    "# Load all sheets\n",
    "sheets = pd.ExcelFile(file_path)\n",
    "sheet_names = sheets.sheet_names\n",
    "print(\"Available Sheets:\", sheet_names)\n",
    "\n",
    "# Load individual sheets\n",
    "admission_data = sheets.parse('sepsis_pt_all_admission details')\n",
    "lab_events = sheets.parse('sepsis_lab_events')\n",
    "microbiology_events = sheets.parse('microbiology events')\n",
    "prescription_data = sheets.parse('prescriptoin')\n",
    "#poe_data = sheets.parse('poe')\n",
    "#poe_details = sheets.parse('poe_detail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87902097-d1fc-4d23-a4b5-e5a002c4353a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant columns\n",
    "admission_data = admission_data[['subject_id','hadm_id', 'admission_type', 'drg_code', 'dx_1_code', 'edhours','heartdisease_flag','kidneydisease_flag']].drop_duplicates()\n",
    "prescription_data = prescription_data[['subject_id','hadm_id', 'drug']].drop_duplicates()\n",
    "\n",
    "prescription_data=prescription_data.reset_index()\n",
    "\n",
    "# Drop rows with missing values in critical columns\n",
    "admission_data.dropna(subset=['subject_id','hadm_id', 'admission_type', 'drg_code', 'dx_1_code', 'edhours','heartdisease_flag','kidneydisease_flag'], inplace=True)\n",
    "prescription_data.dropna(subset=['subject_id','hadm_id', 'drug'], inplace=True)\n",
    "\n",
    "# Merge admissions and prescriptions\n",
    "admission_drug_data = pd.merge(prescription_data, admission_data, on='hadm_id', how='inner')\n",
    "admission_drug_data.rename(columns={'subject_id_x': 'subject_id'}, inplace=True)\n",
    "\n",
    "# Encode categorical variables\n",
    "categorical_features = pd.get_dummies(\n",
    "    admission_drug_data[['admission_type', 'drg_code', 'dx_1_code','heartdisease_flag','kidneydisease_flag']],\n",
    "    drop_first=True\n",
    ")\n",
    "\n",
    "# Scale numerical features (EDHOURS)\n",
    "scaler = StandardScaler()\n",
    "numerical_features = scaler.fit_transform(admission_drug_data[['edhours']])\n",
    "\n",
    "numerical_features = pd.DataFrame(numerical_features, columns=['scaled_edhours'])\n",
    "\n",
    "# TF-IDF for drug names\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "drug_tfidf_matrix = tfidf_vectorizer.fit_transform(admission_drug_data['drug'])\n",
    "\n",
    "# Combine All Features into a Single DataFrame\n",
    "combined_features = pd.concat([categorical_features.reset_index(drop=True), numerical_features.reset_index(drop=True)], axis=1).reset_index(drop=True)\n",
    "\n",
    "print(\"Combined Features Shape:\", combined_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff317a1-9f8d-4bc3-9a73-97e06fdc8284",
   "metadata": {},
   "outputs": [],
   "source": [
    "admission_drug_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb17eef-4cf5-4c5f-85a8-f58e9723f27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### **Step 1: Data Preparation**\n",
    "def prepare_data(admission_drug_data, min_drug_freq=5, min_patient_drugs=3):\n",
    "    \"\"\"\n",
    "    Prepares data by filtering rare drugs, handling missing values, and creating an interaction matrix.\n",
    "\n",
    "    Args:\n",
    "        admission_drug_data (pd.DataFrame): Data containing 'subject_id', 'hadm_id', and 'drug'.\n",
    "        min_drug_freq (int): Minimum number of times a drug must be prescribed to be included.\n",
    "        min_patient_drugs (int): Minimum drugs a patient must have for inclusion.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Processed patient-drug interaction matrix.\n",
    "    \"\"\"\n",
    "    # Remove duplicates & handle missing values\n",
    "    admission_drug_data = admission_drug_data.drop_duplicates().dropna(subset=['subject_id', 'drug'])\n",
    "\n",
    "    # Remove rarely prescribed drugs\n",
    "    drug_counts = admission_drug_data['drug'].value_counts()\n",
    "    rare_drugs = drug_counts[drug_counts < min_drug_freq].index\n",
    "    admission_drug_data = admission_drug_data[~admission_drug_data['drug'].isin(rare_drugs)]\n",
    "\n",
    "    # Aggregate multiple admissions per patient\n",
    "    patient_drug_data = admission_drug_data.groupby(['subject_id', 'drug']).size().reset_index(name='count')\n",
    "\n",
    "    # Remove patients with very few prescriptions\n",
    "    patient_counts = patient_drug_data['subject_id'].value_counts()\n",
    "    patient_drug_data = patient_drug_data[patient_drug_data['subject_id'].isin(patient_counts[patient_counts >= min_patient_drugs].index)]\n",
    "    \n",
    "    # Create interaction matrix (subject_id Ã— drug)\n",
    "    interaction_matrix = patient_drug_data.pivot_table(index=\"subject_id\", columns=\"drug\", values=\"count\", fill_value=0)\n",
    "\n",
    "    return interaction_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c3bcf7-e9fc-42e5-8491-98796e8745cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### **Step 2: Train SVD Model**\n",
    "def train_svd(interaction_matrix, n_components=50):\n",
    "    \"\"\"\n",
    "    Applies SVD for dimensionality reduction.\n",
    "\n",
    "    Args:\n",
    "        interaction_matrix (pd.DataFrame): Patient-drug interaction matrix.\n",
    "        n_components (int): Number of latent features.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (SVD model, latent feature matrix).\n",
    "    \"\"\"\n",
    "    sparse_matrix = csr_matrix(interaction_matrix)  # Convert to sparse for efficiency\n",
    "    svd = TruncatedSVD(n_components=n_components, random_state=42)\n",
    "    latent_matrix = svd.fit_transform(sparse_matrix)\n",
    "\n",
    "    return svd, latent_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38fa8f8-b109-4c81-8e05-c6d77be728d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_drugs_old(patient_id, interaction_matrix, latent_matrix, top_n=5):\n",
    "    if patient_id not in interaction_matrix.index:\n",
    "        return \"Patient ID not found in dataset.\"\n",
    "\n",
    "    patient_index = interaction_matrix.index.get_loc(patient_id)\n",
    "    similarity_scores = np.dot(latent_matrix, latent_matrix[patient_index])\n",
    "\n",
    "    print(f\"Patient Index: {patient_index}\")\n",
    "    print(f\"Similarity Scores: {similarity_scores[:10]}\")  # Print first 10 similarity scores\n",
    "\n",
    "    # Retrieve similar patient indices\n",
    "    similar_patient_indices = np.argsort(similarity_scores)[::-1][1:top_n+1]  # Exclude the patient itself\n",
    "\n",
    "    # Check if similar patients exist\n",
    "    if len(similar_patient_indices) == 0:\n",
    "        print(\"No similar patients found!\")\n",
    "        return None\n",
    "\n",
    "    # Aggregate drug usage from similar patients\n",
    "    similar_patients = interaction_matrix.iloc[similar_patient_indices]\n",
    "    recommended_drugs = similar_patients.mean(axis=0).sort_values(ascending=False).head(top_n)\n",
    "\n",
    "    if recommended_drugs.empty:\n",
    "        print(\"No recommended drugs found!\")\n",
    "        return None\n",
    "\n",
    "    return recommended_drugs\n",
    "\n",
    "def recommend_drugs(patient_id, interaction_matrix, latent_matrix, top_n=5):\n",
    "    if patient_id not in interaction_matrix.index:\n",
    "        return \"Patient ID not found in dataset.\"\n",
    "\n",
    "    # Get the patient index\n",
    "    patient_index = interaction_matrix.index.get_loc(patient_id)\n",
    "\n",
    "    # Compute similarity scores (dot product of latent vectors)\n",
    "    similarity_scores = np.dot(latent_matrix, latent_matrix[patient_index])\n",
    "\n",
    "    print(f\"Patient Index: {patient_index}\")\n",
    "    print(f\"Similarity Scores (first 10): {similarity_scores[:10]}\")  # Debugging output\n",
    "\n",
    "    # Get indices of most similar patients (excluding the patient itself)\n",
    "    similar_patient_indices = np.argsort(similarity_scores)[::-1][1:top_n+1]\n",
    "\n",
    "    # Get corresponding similarity scores\n",
    "    similar_patient_scores = similarity_scores[similar_patient_indices]\n",
    "\n",
    "    if len(similar_patient_indices) == 0:\n",
    "        print(\"No similar patients found!\")\n",
    "        return None\n",
    "\n",
    "    # Aggregate drug usage from similar patients\n",
    "    similar_patients = interaction_matrix.iloc[similar_patient_indices]\n",
    "    recommended_drugs = similar_patients.mean(axis=0).sort_values(ascending=False).head(top_n)\n",
    "\n",
    "    if recommended_drugs.empty:\n",
    "        print(\"No recommended drugs found!\")\n",
    "        return None\n",
    "\n",
    "    # Create a dictionary to store recommendations + similarity scores\n",
    "    result = {\n",
    "        \"recommended_drugs\": recommended_drugs,\n",
    "        \"similar_patients\": {\n",
    "            \"indices\": similar_patient_indices.tolist(),\n",
    "            \"scores\": similar_patient_scores.tolist()\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6e54c1-27b4-4f0c-b723-77924564fd4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545344f7-d2b7-4bc2-bd51-f35122971cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### **Step 4: Running the Pipeline**\n",
    "# Load dataset (Replace with actual dataset)\n",
    "# admission_drug_data = pd.read_csv(\"your_data.csv\")\n",
    "\n",
    "# Data Preparation\n",
    "interaction_matrix = prepare_data(admission_drug_data)\n",
    "#print(interaction_matrix)\n",
    "\n",
    "# Train SVD Model\n",
    "svd_model, latent_matrix = train_svd(interaction_matrix, n_components=50)\n",
    "#print(svd_model)\n",
    "#print(latent_matrix)\n",
    "\n",
    "# Get Recommendations for a Sample Patient\n",
    "patient_id = 10577647  # Replace with actual `subject_id`\n",
    "recommendations = recommend_drugs(patient_id, interaction_matrix, latent_matrix, top_n=10)\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3160200-e406-43cd-91e2-d349450c34ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Events Recommendations\n",
    "### **Step 1: Data Preparation**\n",
    "def prepare_event_data(admission_event_data, min_event_freq=5, min_patient_events=3):\n",
    "    \"\"\"\n",
    "    Prepares data by filtering rare events, handling missing values, and creating an interaction matrix.\n",
    "\n",
    "    Args:\n",
    "        admission_event_data (pd.DataFrame): Data containing 'subject_id', 'hadm_id', and 'event'.\n",
    "        min_event_freq (int): Minimum number of times an event must be recorded to be included.\n",
    "        min_patient_events (int): Minimum events a patient must have for inclusion.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Processed patient-event interaction matrix.\n",
    "    \"\"\"\n",
    "    # Remove duplicates & handle missing values\n",
    "    admission_event_data = admission_event_data.drop_duplicates().dropna(subset=['subject_id', 'spec_type_desc'])\n",
    "\n",
    "    # Remove rare events\n",
    "    event_counts = admission_event_data['spec_type_desc'].value_counts()\n",
    "    rare_events = event_counts[event_counts < min_event_freq].index\n",
    "    admission_event_data = admission_event_data[~admission_event_data['spec_type_desc'].isin(rare_events)]\n",
    "\n",
    "    # Aggregate multiple admissions per patient\n",
    "    patient_event_data = admission_event_data.groupby(['subject_id', 'spec_type_desc']).size().reset_index(name='count')\n",
    "\n",
    "    # Remove patients with very few recorded events\n",
    "    patient_counts = patient_event_data['subject_id'].value_counts()\n",
    "    patient_event_data = patient_event_data[patient_event_data['subject_id'].isin(patient_counts[patient_counts >= min_patient_events].index)]\n",
    "    \n",
    "    # Create interaction matrix (subject_id Ã— event)\n",
    "    interaction_matrix = patient_event_data.pivot_table(index=\"subject_id\", columns=\"spec_type_desc\", values=\"count\", fill_value=0)\n",
    "\n",
    "    return interaction_matrix\n",
    "\n",
    "\n",
    "### **Step 2: Train SVD Model**\n",
    "def train_svd(interaction_matrix, n_components=30):\n",
    "    \"\"\"\n",
    "    Applies SVD for dimensionality reduction.\n",
    "\n",
    "    Args:\n",
    "        interaction_matrix (pd.DataFrame): Patient-event interaction matrix.\n",
    "        n_components (int): Number of latent features.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (SVD model, latent feature matrix).\n",
    "    \"\"\"\n",
    "    sparse_matrix = csr_matrix(interaction_matrix)  # Convert to sparse for efficiency\n",
    "    svd = TruncatedSVD(n_components=n_components, random_state=42)\n",
    "    latent_matrix = svd.fit_transform(sparse_matrix)\n",
    "\n",
    "    return svd, latent_matrix\n",
    "\n",
    "\n",
    "### **Step 3: Event Recommendation**\n",
    "def recommend_events(patient_id, interaction_matrix, latent_matrix, top_n=5):\n",
    "    \"\"\"\n",
    "    Recommends events for a given patient based on similar patients.\n",
    "\n",
    "    Args:\n",
    "        patient_id (int): Patient ID for whom to recommend events.\n",
    "        interaction_matrix (pd.DataFrame): Patient-event interaction matrix.\n",
    "        latent_matrix (np.ndarray): Latent feature matrix from SVD.\n",
    "        top_n (int): Number of recommendations.\n",
    "\n",
    "    Returns:\n",
    "        dict: Recommended events and similar patients.\n",
    "    \"\"\"\n",
    "    if patient_id not in interaction_matrix.index:\n",
    "        return \"Patient ID not found in dataset.\"\n",
    "\n",
    "    # Get the patient index\n",
    "    patient_index = interaction_matrix.index.get_loc(patient_id)\n",
    "\n",
    "    # Compute similarity scores (dot product of latent vectors)\n",
    "    similarity_scores = np.dot(latent_matrix, latent_matrix[patient_index])\n",
    "\n",
    "    print(f\"Patient Index: {patient_index}\")\n",
    "    print(f\"Similarity Scores (first 10): {similarity_scores[:10]}\")  # Debugging output\n",
    "\n",
    "    # Get indices of most similar patients (excluding the patient itself)\n",
    "    similar_patient_indices = np.argsort(similarity_scores)[::-1][1:top_n+1]\n",
    "\n",
    "    # Get corresponding similarity scores\n",
    "    similar_patient_scores = similarity_scores[similar_patient_indices]\n",
    "\n",
    "    if len(similar_patient_indices) == 0:\n",
    "        print(\"No similar patients found!\")\n",
    "        return None\n",
    "\n",
    "    # Aggregate event occurrences from similar patients\n",
    "    similar_patients = interaction_matrix.iloc[similar_patient_indices]\n",
    "    recommended_events = similar_patients.mean(axis=0).sort_values(ascending=False).head(top_n)\n",
    "\n",
    "    if recommended_events.empty:\n",
    "        print(\"No recommended events found!\")\n",
    "        return None\n",
    "\n",
    "    # Create a dictionary to store recommendations + similarity scores\n",
    "    result = {\n",
    "        \"recommended_events\": recommended_events,\n",
    "        \"similar_patients\": {\n",
    "            \"indices\": similar_patient_indices.tolist(),\n",
    "            \"scores\": similar_patient_scores.tolist()\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a116ff-45ae-44f5-8b38-4e78fa62bfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Prepare Data\n",
    "interaction_matrix = prepare_event_data(microbiology_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79af6a4-76f9-4988-b6d8-3d25c0e77457",
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bc97e5-5e47-4694-9d92-586a252f9193",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Train SVD Model\n",
    "svd_model, latent_matrix = train_svd(interaction_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a59d37-399f-4cfa-aff0-4b07756be42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Recommendations for a Sample Patient\n",
    "patient_id = 10577647  # Replace with actual `subject_id`\n",
    "recommendations = recommend_events(patient_id, interaction_matrix, latent_matrix, top_n=10)\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652f3d74-d610-46b9-b94d-f2c72dab60b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
